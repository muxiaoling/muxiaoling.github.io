<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>MySQL中datetime和timestamp的区别？</title>
    <url>/p/773a7712/</url>
    <content><![CDATA[<h2 id="表示范围"><a href="#表示范围" class="headerlink" title="表示范围"></a>表示范围</h2><table>
<thead>
<tr>
<th>类型</th>
<th>表示范围</th>
</tr>
</thead>
<tbody><tr>
<td>datetime</td>
<td>‘1000-01-01 00:00:00.000000’ to ‘9999-12-31 23:59:59.999999’</td>
</tr>
<tr>
<td>timestamp</td>
<td>‘1970-01-01 00:00:01.000000’ to ‘2038-01-19 03:14:07.999999’</td>
</tr>
</tbody></table>
<p>timestamp时间戳，表示当前时间到Unix元年（1970 年 1 月 1 日 0 时 0 分 0 秒）的秒数</p>
<p>对于某些时间的计算，如果是以 <code>datetime</code> 的形式会比较困难，假如某人是 <code>1994-1-20 06:06:06</code> 出生，现在的时间是 <code>2021-10-1 20:04:50</code> ，那么要计算存活了多少秒 用 <code>datetime</code> 还需要函数进行转换，但是 <code>timestamp</code> 直接相减就行。</p>
<h2 id="时区"><a href="#时区" class="headerlink" title="时区"></a>时区</h2><p><code>timestamp</code> 只占 4 个字节，而且是以<code>utc</code>的格式储存， 它会自动检索当前时区并进行转换。如果储存时的时区和检索时的时区不一样，那么拿出来的数据也不一样。</p>
<p><code>datetime</code>以 8 个字节储存，不会进行时区的检索。存的时间什么拿到的就是什么时间。</p>
<h2 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h2><p><strong>TIMESTAMP 使用场景：计算飞机飞行时间</strong></p>
<p>一架飞机，从中国北京起飞，降落在美国纽约，计算它从北京飞往纽约的飞行时间。飞机在北京时间 2021-10-10 11:05:00 从北京起飞，在纽约时间 2021-10-10 09:50:00 降落</p>
<p>这个场景中，如果使用 <code>TIMESTAMP</code> 来存时间，起飞和降落时间的值，都会被转换成 UTC 时间，所以它们直接相减即可获得结果。但如果使用 <code>DATATIME</code> 格式存时间，还需要进行转换，才可以完成，容易出错。</p>
<p><strong>DATATIME 使用场景：记录信息修改时间</strong></p>
<p>如果只是记录文件修改时间，最后更新时间这种不涉及加减转换的情况，用 <code>DATATIME</code> 来存更直接，更方便，可读性高，直接读取存储时的时间，不容易出错。</p>
<h2 id="存储相关"><a href="#存储相关" class="headerlink" title="存储相关"></a>存储相关</h2><ul>
<li><p><code>TIMESTAMP</code> ：4 个字节整型，存储 UTC 时间秒（小数秒+3 个字节）</p>
</li>
<li><p><code>DATETIME</code>：</p>
<ol>
<li><p><code>（5.6.4 之前）</code></p>
<blockquote>
<p>8 个字节， 其中 4 个字节整型 YYYY×10000 + MM×100 + DD 和 4 个字节整型 HH×10000 + MM×100 + SS</p>
</blockquote>
</li>
<li><p><code>（5.6.4 之后）</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> 1 bit  符号位          (1= 整数, 0=负数)</span><br><span class="line">17 bits year*13+month  (year 0-9999, month 0-12)</span><br><span class="line"> 5 bits day            (0-31)</span><br><span class="line"> 5 bits hour           (0-23)</span><br><span class="line"> 6 bits minute         (0-59)</span><br><span class="line"> 6 bits second         (0-59)</span><br><span class="line">---------------------------</span><br><span class="line">40 bits = 5 bytes</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ul>
<table>
<thead>
<tr>
<th>类型</th>
<th>占据字节</th>
<th>表示形式</th>
</tr>
</thead>
<tbody><tr>
<td>timestamp</td>
<td>4 字节</td>
<td>yyyy-mm-dd hh:mm:ss</td>
</tr>
<tr>
<td>datetime</td>
<td>8(5) 字节</td>
<td>yyyy-mm-dd hh:mm:ss</td>
</tr>
</tbody></table>
<p><strong>使用 <code>now()</code> 存储当前时间时，保存的实际值，是否与当前计算机时间一致？</strong></p>
<ul>
<li><code>TIMESTAMP</code>：可能不一致。存储值会被转换成 UTC 时间值再存入数据库。</li>
<li><code>DATETIME</code>：与当前时间是一致的。</li>
</ul>
<p><strong>如果存入的是 <code>NULL</code> 时，两个类型如何存储？</strong></p>
<ul>
<li><code>TIMESTAMP</code>：会自动存储当前时间（ <code>now()</code> ）。</li>
<li><code>DATETIME</code>：不会自动存储当前时间，会直接存入 <code>NULL</code> 值。</li>
</ul>
<h3 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h3><p>1.新建一个包含<code>TIMESTAMP</code> &amp; <code>DATATIME</code> 两个数据类型字段的<code>time_demo</code>表：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CREATE TABLE time_demo(</span><br><span class="line">	`timestamp` timestamp,</span><br><span class="line">	`datetime` datetime</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p>2.往表中插入三组数据，分别是null值，当前时间now()，指定时间</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">insert into time_demo values</span><br><span class="line">(NULL,NULL),</span><br><span class="line">(now(),now()),</span><br><span class="line">(&#x27;19970701171207&#x27;,&#x27;19970701171207&#x27;);</span><br></pre></td></tr></table></figure>

<p>3.使用 <code>SELECT</code> 看一下数据库中的存储结果：</p>
<p>MySQL8版本的数据为：</p>
<p><img src="https://s2.loli.net/2022/12/01/Bl95Q8NPevjw4cF.png" alt="image-20221201124742215"></p>
<p>MySQL5.7版本的数据为：</p>
<p><img src="https://s2.loli.net/2022/12/01/tLMEImcJigVWn3T.png" alt="image-20221201124948332"></p>
<p>4.将时区从+8区改为+10区，并查询数据</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">set time_zone = &#x27;+10:00&#x27;;</span><br><span class="line">select * from time_demo;</span><br></pre></td></tr></table></figure>

<p><img src="https://s2.loli.net/2022/12/01/DAzKrSLBe4cx5yp.png" alt="image-20221201125207263"></p>
<p><strong>实验结论：</strong></p>
<ul>
<li>向数据插入 <code>NULL</code> 时：<code>timestamp</code>存入了当前时间（MySQL8版本为NULL），而<code>datetime</code> 直接存了 <code>NULL</code> 本身。</li>
<li>向数据插入 <code>now()</code> 时：更改时区后，<code>timestamp</code> 随时区变化，<code>datetime</code> 没有变化。</li>
<li>数据库直接插入时间值：更改时区后，<code>timestamp</code> 随时区变化，<code>datetime</code> 没有变化。</li>
</ul>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL中的count(*),count(1),count(字段)有什么区别？</title>
    <url>/p/5fed1c16/</url>
    <content><![CDATA[<h2 id="count-是什么？"><a href="#count-是什么？" class="headerlink" title="count()是什么？"></a>count()是什么？</h2><p>当我们对一张数据表的记录数量进行统计时，会使用到count()函数。count() 是一个聚合函数，函数的参数不仅可以是字段名，也可以是其他任意表达式，该函数作用是<strong>统计符合查询条件的记录中，函数指定的参数不为 NULL 的记录有多少个</strong>。</p>
<p>count函数的使用方式有多种：count(*)、count(1)、count(字段) 等。<span id="more"></span></p>
<h2 id="哪种count-性能最好？"><a href="#哪种count-性能最好？" class="headerlink" title="哪种count()性能最好？"></a>哪种count()性能最好？</h2><h3 id="简单了解一下count函数"><a href="#简单了解一下count函数" class="headerlink" title="简单了解一下count函数"></a>简单了解一下count函数</h3><p>要理解这个问题，需要弄清楚count的原理。说明：我所使用的MySQL存储引擎是基于InnoDB的。</p>
<p>如果count()函数的参数是一个普通字段名：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="built_in">count</span>(name) <span class="keyword">from</span> <span class="keyword">user</span>;</span><br></pre></td></tr></table></figure>

<p>这条语句是统计user表中，name字段不为null的记录有多少条。也就是说name字段如果为null，将不会被统计进去。</p>
<p>如果count()函数的参数是数字1，是什么意思？</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">from</span> <span class="keyword">user</span>;</span><br></pre></td></tr></table></figure>

<p>这条语句的意思是统计user表中，1这个表达式不为null的记录 有多少条。这个1就是就相当于一个表达式，他永远不为null，所以这条语句就是统计user表有多少条记录。</p>
<p>如果将count()参数换成<code>*</code>是什么意思？</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">from</span> <span class="keyword">user</span>;</span><br></pre></td></tr></table></figure>

<p>看到<code>*</code>这个字符的时候你可能会和<code>select *</code>这条语句相对应，<strong>其实并不是这样的</strong>。</p>
<p>count(*)其实是相当于count(0)的意思，当MySQL解析count(*)时，会将*参数转化为参数 0 来处理。</p>
<p>而0和1一样，同样作为永不为null的表达式来说，在意思上就可以理解为获取表中所有记录的条数。count(*)在性能上跟count(1)没有差异性。</p>
<p>引用MySQL 5.7官方手册的一句话：</p>
<blockquote>
<p><em>InnoDB handles SELECT COUNT(*) and SELECT COUNT(1) operations in the same way. There is no performance difference.</em></p>
<p>译：<em>InnoDB以相同的方式处理SELECT COUNT（*）和SELECT COUNT（1）操作，没有性能上的差异</em></p>
</blockquote>
<p>并且MySQL对count(*)和count(1)还进行了优化，当存在多个二级索引时，优化器会使用key_len 最小的二级索引进行扫描。（注意：只有当没有二级索引的时候，才会采用主键索引来进行统计。）</p>
<p>如果有二级索引那么会采用二级索引来进行统计，因为Inode存储引擎中索引文件采用B+树的形式进行存储，Innodb引擎中聚簇索引存储的是一条完整的数据字段，二级索引存储的是部分字段，当需要进行count(*)统计时，要将磁盘中的数据，以页为单位（一页&#x3D;16kb）加载到内存中，采用二级索引可以一次加载更多的数据，减少IO次数。</p>
<h3 id="count-1-执行过程"><a href="#count-1-执行过程" class="headerlink" title="count(1) 执行过程"></a>count(1) 执行过程</h3><p>以下面这条语句作为例子：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">from</span> <span class="keyword">user</span>;</span><br></pre></td></tr></table></figure>

<p>针对上面这条语句，这张图表中不存在二级索引时的执行计划：</p>
<p><img src="https://s2.loli.net/2022/11/01/HhelurAwSoJB9aW.png" alt="image-20221101165033747"></p>
<p>这张图是创建了二级索引时的执行计划：</p>
<p><img src="https://s2.loli.net/2022/11/01/JAVDNGwZkqjtvWI.png" alt="image-20221101164946055"></p>
<p>InnoDB 循环遍历聚簇索引（主键索引），将读取到的记录返回给 server 层，<strong>但是不会读取记录中的任何字段的值</strong>，因为 count 函数的参数是 1，不是字段，所以不需要读取记录中的字段值。参数 1 很明显并不是 NULL，因此 server 层每从 InnoDB 读取到一条记录，就将 count 变量加 1。</p>
<p>可以看到，count(1) 相比 count(主键字段) 少一个步骤，就是不需要读取记录中的字段值，所以通常会说 count(1) 执行效率会比 count(主键字段) 高一点。</p>
<p>但是，如果表里有二级索引时，InnoDB 循环遍历的对象就二级索引了。</p>
<h3 id="count-执行过程"><a href="#count-执行过程" class="headerlink" title="count(*)执行过程"></a>count(*)执行过程</h3><p><strong>count(*) 其实等于 count(<code>0</code>)<strong>，也就是说，当你使用 count(*) 时，MySQL 会将 <code>*</code> 参数转化为参数 0 来处理。所以，</strong>count(*) 执行过程跟 count(1) 执行过程基本一样的</strong>，性能没有什么差异。</p>
<p>当没有二级索引的时候，同样也是采用主键索引来进行统计。</p>
<h3 id="count-字段-执行过程"><a href="#count-字段-执行过程" class="headerlink" title="count(字段)执行过程"></a>count(字段)执行过程</h3><p>以下面这条语句为例：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="operator">/</span><span class="operator">/</span> name不是索引，普通字段</span><br><span class="line"><span class="keyword">select</span> <span class="built_in">count</span>(name) <span class="keyword">from</span> <span class="keyword">user</span>;</span><br></pre></td></tr></table></figure>

<p>对于这个不存在二级索引时的查询，会采用全表扫描的方式来计数，所以他的执行效率是比较差的。</p>
<p><img src="https://s2.loli.net/2022/11/01/Mbes694BWqIQXFn.png" alt="image-20221101170515004"></p>
<h3 id="综上所述"><a href="#综上所述" class="headerlink" title="综上所述"></a>综上所述</h3><p>count(1)、 count(*)、 count(主键字段)在执行的时候，如果表里存在二级索引，优化器就会选择二级索引进行扫描。所以，如果要执行 count(1)、 count(*)、 count(主键字段) 时，尽量在数据表上建立二级索引，这样优化器会自动采用 key_len 最小的二级索引进行扫描，相比于扫描主键索引效率会高一些。尽量避免使用 count(字段) 来统计记录个数，因为它的效率是最差的，会采用全表扫描的方式来统计。</p>
<h2 id="为什么要采用遍历的方式来计数？"><a href="#为什么要采用遍历的方式来计数？" class="headerlink" title="为什么要采用遍历的方式来计数？"></a>为什么要采用遍历的方式来计数？</h2><p>前面的案例都是基于 Innodb 存储引擎来说明的，但是在 MyISAM 存储引擎里，执行 count 函数的方式是不一样的，通常在没有任何查询条件下的 count(*)，MyISAM 的查询速度要明显快于 InnoDB。</p>
<p>使用 MyISAM 引擎时，执行 count 函数只需要 O(1 )复杂度，这是因为每张 MyISAM 的数据表都有一个 meta 信息有存储了row_count值，由表级锁保证一致性，所以直接读取 row_count 值就是 count 函数的执行结果。</p>
<p><strong>而 InnoDB 存储引擎是支持事务的，同一个时刻的多个查询，由于多版本并发控制（MVCC）的原因，InnoDB 表“应该返回多少行”也是不确定的，所以无法像 MyISAM一样，只维护一个 row_count 变量。</strong></p>
<h2 id="如何弥补count-的不足"><a href="#如何弥补count-的不足" class="headerlink" title="如何弥补count(*)的不足"></a>如何弥补count(*)的不足</h2><p>如果对于一张数据量大的表来说，其实是很不好的。因为数据库会逐条统计得到答案。</p>
<p>所以面对大表的记录统计，我们可以采用两种方式来统计：①估计法 ②额外表保存计数值</p>
<h3 id="估计法"><a href="#估计法" class="headerlink" title="估计法"></a>估计法</h3><p>业务对于统计个数不需要很精确，可以使用 <code>show table status</code> 或者 <code>explain</code> 命令来表进行估算。</p>
<p>执行 explain 命令效率是很高的，因为它并不会真正的去查询。</p>
<blockquote>
<p>mysql-5.5之前：</p>
<p>首先找到查询第一个记录所在的page（记为PLeft），统计PLeft里的记录数（记为Records_PLeft），之后找到最后一个记录所在的page（记为PRight），统计PRight的记录数（Records_PRight），之后将Records_PLeft与Records_PRight取平均，最后乘以总共的page数目（记为Page_Num）。公式如下：</p>
<figure class="highlight mathematica"><table><tr><td class="code"><pre><span class="line"><span class="variable">Rows</span> <span class="operator">=</span> <span class="punctuation">(</span><span class="punctuation">(</span><span class="type">Records_PLeft</span> <span class="operator">+</span> <span class="type">Records_PRight</span><span class="punctuation">)</span><span class="operator">/</span><span class="number">2</span><span class="punctuation">)</span><span class="operator">*</span><span class="type">Page_Num</span></span><br></pre></td></tr></table></figure>
</blockquote>
<blockquote>
<p>mysql-5.5之后：</p>
<p>上述预估偏差大的关键在于有偏，而有偏的关键在于采样的page数太少了，事实上只采样了边界2个，新算法的思路很简单，增加采样数目，比如采样10个page，这样可以在一定程度上降低偏差。</p>
<p>具体来说，mysql除了边界2个外，还沿着左侧page往右连续查找8个page，如果总的page数目小于等于10个，那么预估的Rows和真实的Rows一致。虽然该方式在一定程度上缓解了有偏的问题，但是不准确还是存在的。公式如下：</p>
<figure class="highlight mathematica"><table><tr><td class="code"><pre><span class="line"><span class="variable">Rows</span> <span class="operator">=</span> <span class="punctuation">(</span><span class="punctuation">(</span><span class="type">Records_PLeft</span> <span class="operator">+</span>  <span class="type">Records_P1</span> <span class="operator">+</span> <span class="type">Records_P2</span> <span class="operator">+</span> <span class="operator">...</span> <span class="operator">+</span> <span class="type">Records_P8</span> <span class="operator">+</span> <span class="type">Records_PRight</span><span class="punctuation">)</span><span class="operator">/</span><span class="number">10</span><span class="punctuation">)</span><span class="operator">*</span><span class="type">Page_Num</span></span><br></pre></td></tr></table></figure>
</blockquote>
<h3 id="额外表保存计数值"><a href="#额外表保存计数值" class="headerlink" title="额外表保存计数值"></a>额外表保存计数值</h3><p>对于记录数较多的表，如果是想精确的获取表的记录总数，我们可以将这个计数值保存到单独的一张计数表中。</p>
<p>当我们在数据表插入一条记录的同时，将计数表中的计数字段 + 1，在新增和删除操作时，我们需要额外维护这个计数表。</p>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>缓存常见问题</title>
    <url>/p/5e0bc5d1/</url>
    <content><![CDATA[<h2 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h2><p>缓存击穿某个热点key过期，导致大量请求打到数据库上，导致数据库压力激增的一种现象。</p>
<h3 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h3><p>分布式锁：对访问数据库的大量key加分布式锁，同一时刻，只允许一个请求访问，访问过后将结果缓存到redis中，这样后来的请求便可以直接获取redis中的结果。</p>
<span id="more"></span>

<h2 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h2><p>缓存雪崩是短时间内，缓存中的key大面积过期，导致所有请求打到数据库中。</p>
<h3 id="解决方法-1"><a href="#解决方法-1" class="headerlink" title="解决方法"></a>解决方法</h3><p>可以给不同key的过期时间加上随机值，防止某个时间大量的key同时过期。对应热key，可以设置成永不过期的方式。</p>
<h2 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h2><p>缓存穿透是大量请求中的key在缓存中不存在，数据库中也不存在，导致数据库压力过大的一种现象。</p>
<h3 id="解决方法-2"><a href="#解决方法-2" class="headerlink" title="解决方法"></a>解决方法</h3><p><strong>缓存空对象</strong></p>
<p>redis是key-value存储的键值对数据库，可以将不存在的key缓存起来，下次访问该key时便不会走数据库。但是如果大量key都是不同的，那就会造成redis中缓存大量无效的key，浪费内存。</p>
<p><strong>布隆过滤器</strong></p>
<p>采用位数组的方式，不直接存储元素，而是存储元素是否存在的状态 。</p>
<p>具体思想：</p>
<ul>
<li><p>一个初始状态都为0的位数组</p>
<p><img src="https://s2.loli.net/2022/10/27/ehrDagX5YdnLHG6.png" alt="位数组"></p>
</li>
<li><p>元素经过N个散列函数计算出元素在数组当中的位置，并且将数组中对应位置的0改成1 </p>
<p><img src="https://s2.loli.net/2022/10/27/qWPKFhHbYlO51jX.png" alt="散列"></p>
</li>
<li><p>如果此时需要判断元素X是否存在，那么元素X也会经过这N个散列函数的运算而得到数组中的若干个位置，如果得到的若干个位置中的值均为1，那么则证明元素X很可能存在与集合当中，反之则证明元素X一定不存在于集合当中。 </p>
<p><img src="https://s2.loli.net/2022/10/27/KOSL2IePpTxFYwi.png" alt="不存在"></p>
</li>
</ul>
<p>优缺点：</p>
<p>优点：在空间和时间方面，都有着巨大的优势。因为布隆过滤器不是存完整的数据，而存是一个二进制向量，能节省大量的内存空间。在时间复杂度方面，由于计算时是根据散列函数计算查询的，那么假设有N个散列函数，那么时间复杂度就是O(N)；</p>
<p>缺点：存在一定的误判（存进布隆过滤器里的元素越多，误判率越高）；不能删除布隆过滤器里的元素 。</p>
<p><strong>布隆过滤器应用</strong></p>
<ul>
<li><p>Redission实现布隆过滤器</p>
<ol>
<li><p>引入依赖</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!--redisson--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.redisson<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>redisson<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.13.6<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>编写配置类</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">RedissonConfig</span> &#123;</span><br><span class="line">    <span class="comment">//redis的ip地址</span></span><br><span class="line">    <span class="meta">@Value(&quot;$&#123;spring.redis.host&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> String redisHost;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//redis端口号</span></span><br><span class="line">    <span class="meta">@Value(&quot;$&#123;spring.redis.port&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> String redisPort;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//redis密码</span></span><br><span class="line">    <span class="meta">@Value(&quot;$&#123;spring.redis.password&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> String redisPassword;</span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="keyword">public</span> RedissonClient <span class="title function_">redissonClient</span><span class="params">()</span>&#123;</span><br><span class="line">        <span class="type">Config</span> <span class="variable">config</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Config</span>();</span><br><span class="line">        config.useSingleServer().setAddress(<span class="string">&quot;redis://&quot;</span>+ redisHost + <span class="string">&quot;:&quot;</span> + redisPort)</span><br><span class="line">        .setPassword(redisPassword);</span><br><span class="line">        <span class="comment">// 创建RedissonClient对象</span></span><br><span class="line">        <span class="keyword">return</span> Redisson.create(config);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>应用</p>
<p>利用单例模式将RBloomFilter封装成一个工具类，以便项目使用。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BloomFilterUtil</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Redisson redisson;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">BloomFilterUtil</span><span class="params">(Redisson redisson)</span>&#123;</span><br><span class="line">        BloomFilterUtil.redisson = redisson;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">private</span> <span class="title function_">BloomFilterUtil</span> <span class="params">()</span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">volatile</span> RBloomFilter&lt;Long&gt; bloomFilter;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> RBloomFilter&lt;Long&gt; <span class="title function_">getBloomFilter</span><span class="params">(String name)</span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (bloomFilter == <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">synchronized</span> (BloomFilterUtil.class) &#123;</span><br><span class="line">                <span class="keyword">if</span> (bloomFilter == <span class="literal">null</span>) &#123;</span><br><span class="line">                    bloomFilter = redisson.getBloomFilter(name);</span><br><span class="line">                    bloomFilter.tryInit(<span class="number">100000000</span>,<span class="number">0.04</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> bloomFilter;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">addElement</span><span class="params">(Long element, String name)</span> &#123;</span><br><span class="line">        getBloomFilter(name).add(element);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="type">boolean</span> <span class="title function_">contains</span><span class="params">(Long element, String name)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> getBloomFilter(name).contains(element);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ul>
]]></content>
      <categories>
        <category>缓存数据库</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis持久化技术详解</title>
    <url>/p/b560d14e/</url>
    <content><![CDATA[<h2 id="AOF持久化"><a href="#AOF持久化" class="headerlink" title="AOF持久化"></a>AOF持久化</h2><h3 id="AOF持久化介绍"><a href="#AOF持久化介绍" class="headerlink" title="AOF持久化介绍"></a>AOF持久化介绍</h3><p>Redis 每执行一条写操作命令，就把该命令以追加的方式写入到一个日志文件里，就是 Redis 里的 <strong>AOF(*Append Only File*)</strong> 持久化功能。</p>
<p><strong>AOF日志文件内容解释：</strong></p>
<p>「<code>*3</code>」表示当前命令有三个部分，每部分都是以「<code>$+数字</code>」开头，后面紧跟着具体的命令、键或值。然后，这里的「<code>数字</code>」表示这部分中的命令、键或值一共有多少字节。 <span id="more"></span></p>
<p>eg：「<code>$3 set</code>」表示这部分有 3 个字节，也就是「<code>set</code>」命令这个字符串的长度。</p>
<p><img src="https://s2.loli.net/2022/11/11/hYiOrEdF9nRBDWz.png" alt="image-20221111204423513"></p>
<p><strong>Redis 是先执行写操作命令，再将命令记录到日志文件的好处：</strong></p>
<ul>
<li><strong>避免出现记录错误命令的情况</strong>：先执行命令，如果命令执行成功，就说明这条命令是符合语法规则的，避免了记录日志时进行冗余的语法检查。</li>
<li><strong>不会阻塞当前命令的执行</strong>：因为当写操作命令执行成功后，才会将命令记录到 AOF 日志。</li>
</ul>
<p><strong>AOF持久化功能的潜在风险</strong>：</p>
<ul>
<li>执行写操作命令和记录日志是两个过程，那当 Redis 在还没来得及将命令写入到硬盘时，服务器发生宕机了，这个数据就会有<strong>丢失的风险</strong>。</li>
<li>由于写操作命令执行成功后才记录到 AOF 日志，所以不会阻塞当前写操作命令的执行，但是因为将命令写入到日志的这个操作也是在主进程完成的，<strong>可能会阻塞「下一个」命令的执行</strong>。</li>
</ul>
<p><img src="https://s2.loli.net/2022/11/11/RbxrVBMjG8wdKpk.png" alt="image-20221111210203644"></p>
<p>如果在将日志内容写入到硬盘时，服务器的硬盘的 I&#x2F;O 压力太大，就会导致写硬盘的速度很慢，进而阻塞住了，也就会导致后续的命令无法执行。</p>
<p>认真分析一下，其实这两个风险都有一个共性，都跟「 AOF 日志写回硬盘的时机」有关。</p>
<h3 id="三种写回策略"><a href="#三种写回策略" class="headerlink" title="三种写回策略"></a>三种写回策略</h3><p>Redis 写入 AOF 日志的过程，如下图：</p>
<p><img src="https://s2.loli.net/2022/11/11/cvf4IkpQuatJEYb.png" alt="image-20221111210725788"></p>
<ol>
<li><p>Redis 执行完写操作命令后，会将命令追加到 <code>server.aof_buf</code> 缓冲区；</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">redisServer</span> &#123;</span>    </span><br><span class="line">	sds aof_buf;  <span class="comment">/*AOF缓冲区，在进入事件循环之前写入*/</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>然后通过 write() 系统调用，将 aof_buf 缓冲区的数据写入到 AOF 文件，此时数据并没有写入到硬盘，而是拷贝到了内核缓冲区 PageCache，等待内核将数据写入硬盘；</p>
</li>
<li><p>具体内核缓冲区的数据什么时候写入到硬盘，由内核决定。</p>
</li>
</ol>
<p>在 <code>redis.conf</code> 配置文件中的 <code>appendfsync</code> 配置项可以有以下 3 种参数可填，这3 种写回硬盘的策略，控制的就是上面说的第三步的过程：</p>
<ul>
<li><p><strong>always</strong>：命令写入 aof_buf 后立即调用系统 write 操作和系统 fsync 操作同步到 AOF 文件，fsync 完成后线程返回。这种情况下，每次有写命令都要同步到 AOF 文件，硬盘 IO 成为性能瓶颈，Redis 只能支持大约几百TPS写入，严重降低了 Redis 的性能；即便是使用固态硬盘（SSD），每秒大约也只能处理几万个命令，而且会大大降低 SSD 的寿命。可靠性较高，数据基本不丢失。</p>
</li>
<li><p><strong>no</strong>：命令写入 aof_buf 后调用系统 write 操作，不对 AOF 文件做 fsync 同步；同步由操作系统负责，通常同步周期为30秒。这种情况下，文件同步的时间不可控，且缓冲区中堆积的数据会很多，数据安全性无法保证。</p>
</li>
<li><p><strong>everysec</strong>：命令写入 aof_buf 后调用系统 write 操作，write 完成后线程返回；fsync 同步文件操作由专门的线程每秒调用一次。everysec 是前述两种策略的折中，是性能和数据安全性的平衡，因此是 Redis 的默认配置，也是我们推荐的配置。</p>
</li>
</ul>
<p>这 3 种写回策略都无法能完美解决「主进程阻塞」和「减少数据丢失」的问题，因为两个问题是对立的，偏向于一边的话，就会要牺牲另外一边，原因如下：</p>
<ul>
<li><strong>always 策略</strong>：能最大程度保证数据不丢失，但是由于它每执行一条写操作命令就同步将 AOF 内容写回硬盘，这样还是可能造成主进程的阻塞；</li>
<li><strong>no 策略</strong>，是交由操作系统来决定何时将 AOF 日志内容写回硬盘，相比于 always 策略性能较好，但是操作系统写回硬盘的时机是不可预知的，如果 AOF 日志内容没有写回硬盘，一旦服务器宕机，就会丢失这个时间段内的命令数据。</li>
<li><strong>everysec 策略</strong>：是折中的一种方式，避免了 always 策略的阻塞风险，也比no 策略更能避免数据丢失，但是如果上一秒的写操作命令日志没有写回到硬盘，发生了宕机，这一秒内的数据自然也会丢失。</li>
</ul>
<p><strong>三种策略的实现：</strong></p>
<blockquote>
<p>Linux 操作系统中为了提升性能，使用了页缓存（page cache）。当我们将 aof_buf 的内容写到磁盘上时，此时数据并没有真正的落盘，而是在 page cache 中，为了将 page cache 中的数据真正落盘，需要执行 fsync &#x2F; fdatasync 命令来强制刷盘。这边的文件同步做的就是刷盘操作，或者叫文件刷盘可能更容易理解一些。</p>
</blockquote>
<p>这三种策略只是在控制 <code>fsync()</code> 函数的调用时机。</p>
<p>当应用程序向文件写入数据时，内核通常先将数据复制到内核缓冲区中，然后排入队列，然后由内核决定何时写入硬盘。</p>
<img src="https://s2.loli.net/2022/11/11/uWLeg9jHS1kcPrJ.png" alt="img" style="zoom:67%;" />

<p>如果想要应用程序向文件写入数据后，能立马将数据同步到硬盘，就可以调用 <code>fsync()</code> 函数，这样内核就会将内核缓冲区的数据直接写入到硬盘，等到硬盘写操作完成后，该函数才会返回。</p>
<ul>
<li>always 策略就是每次调用write()写入 page cache后，<strong>就立即执行 fsync() 函数</strong>；</li>
<li>no 策略就是调用系统 write 操作后，<strong>不执行 fsync() 函数</strong>。同步操作由操作系统负责；</li>
<li>everysec 策略就会创建一个<strong>后台异步线程来每秒调用 fsync() 函数</strong>；</li>
</ul>
<h3 id="AOF重写机制"><a href="#AOF重写机制" class="headerlink" title="AOF重写机制"></a>AOF重写机制</h3><p>因为 AOF 里记录的都是每一次写命令，例如执行 set k1 v1，set k1 v2，其实我们只关心数据的最终版本 v2 就可以了。</p>
<p><code>AOF重写机制</code>正是利用了这个特点，在 AOF 体积越来越大时（超过设定阈值），Redis 就会定期重写一份新的 AOF。重写工作完成后，就会将新的 AOF 文件覆盖现有的 AOF 文件，这就相当于压缩了 AOF 文件，使得 AOF 文件体积变小了。</p>
<blockquote>
<p>相关参数：</p>
<ul>
<li>aof_current_size：表示当前 AOF 文件空间</li>
<li>aof_base_size：表示上一次重写后 AOF 文件空间</li>
<li>auto-aof-rewrite-min-size: 表示运行 AOF 重写时文件的最小体积，默认为64MB</li>
<li>auto-aof-rewrite-percentage: 表示当前 AOF 重写时文件空间（aof_current_size）超过上一次重写后 AOF 文件空间（aof_base_size）的比值多少后会重写。</li>
</ul>
</blockquote>
<p><strong>同时满足下面两个条件，则触发 AOF 重写机制：</strong></p>
<ul>
<li>aof_current_size 大于 auto-aof-rewrite-min-size</li>
<li>当前 AOF 相比上一次 AOF 的增长率：(aof_current_size - aof_base_size)&#x2F;aof_base_size 大于或等于 auto-aof-rewrite-percentage</li>
</ul>
<p><strong>重写流程：</strong></p>
<blockquote>
<ol>
<li><p>bgrewriteaof 触发重写，判断是否存在 bgsave 或者 bgrewriteaof 正在执行，存在则等待其执行结束再执行</p>
</li>
<li><p>主进程 fork 子进程，防止主进程阻塞无法提供服务，类似 RDB</p>
</li>
<li><p>子进程遍历 Redis 内存快照中数据写入临时 AOF 文件，同时会将新的写指令写入 aof_buf 和 aof_rewrite_buf 两个缓冲区，前者是为了写回旧的 AOF 文件，后者是为了后续刷新到临时 AOF 文件中，防止快照内存遍历时新的写入操作丢失</p>
</li>
<li><p>子进程结束临时 AOF 文件写入后，通知主进程</p>
</li>
<li><p>主进程会将上面 3 中的 aof_rewirte_buf 缓冲区中的数据写入到子进程生成的临时 AOF 文件中</p>
</li>
<li><p>主进程使用临时 AOF 文件替换旧 AOF 文件，完成整个重写过程</p>
</li>
</ol>
</blockquote>
<p><strong>新的 AOF 文件覆盖现有的 AOF 文件原因：</strong></p>
<p>防止AOF 重写失败，对现有的AOF文件造成影响。所以 AOF 重写过程，先重写到新的 AOF 文件，重写失败的话，就直接删除这个文件就可以了。</p>
<p><strong>AOF后台重写</strong></p>
<p>写入 AOF 日志的操作虽然是在主进程完成的，因为它写入的内容不多，所以一般不太影响命令的操作。</p>
<p>但是在触发 AOF 重写时，会读取所有缓存的键值对，并生成命令的最终版本，生成新的AOF文件代替原来的AOF文件。这个过程是很耗时的，所以<strong>重写AOF文件的过程是由后台子进程bgrewriteaof来完成的</strong></p>
<p><strong>采用后台子进程的好处：</strong></p>
<ul>
<li>避免阻塞主进程：子进程进行 AOF 重写期间，主进程可以继续处理命令请求；</li>
<li>子进程带有主进程的数据副本，这里使用子进程而不是线程，因为如果是使用线程，多线程之间会共享内存，那么在修改共享内存数据的时候，需要通过加锁来保证数据的安全，而这样就会降低性能。而使用子进程，创建子进程时，父子进程是共享内存数据的，不过这个共享的内存只能以只读的方式，而当父子进程任意一方修改了该共享内存，就会发生<strong>「写时复制」</strong>，于是<strong>父子进程就有了独立的数据副本，就不用加锁来保证数据安全</strong>。</li>
</ul>
<p><strong>子进程是怎么拥有主进程一样的数据副本的呢？</strong></p>
<p>主进程在通过 <code>fork</code> 系统调用生成 bgrewriteaof 子进程时，操作系统会把主进程的「<strong>页表</strong>」复制一份给子进程，这个页表记录着虚拟地址和物理地址映射关系，而不会复制物理内存，也就是说，两者的虚拟空间不同，但其对应的物理空间是同一个。</p>
<blockquote>
<p>fork()命令作用</p>
<ol>
<li><p>Linux 操作系统中的程序，fork 会产生一个和父进程完全相同的子进程。子进程与父进程所有的数据均一致，但是子进程是一个全新的进程，与原进程是父子进程关系。</p>
</li>
<li><p>出于效率考虑，Linux 操作系统中使用 COW(Copy On Write)写时复制机制，fork 子进程一般情况下与父进程共同使用一段物理内存，只有在进程空间中的内存发生修改时，内存空间才会复制一份出来。</p>
</li>
</ol>
</blockquote>
<p><img src="https://s2.loli.net/2022/11/14/UZhxYQHAl8EoRat.png" alt="image-20221114212904970"></p>
<h3 id="写时复制"><a href="#写时复制" class="headerlink" title="写时复制"></a>写时复制</h3><p><strong>写时复制的原理：</strong></p>
<p>当创建子进程时，父子进程指向相同的 <code>物理内存</code>，而不是将父进程所占用的 <code>物理内存</code> 复制一份。</p>
<p>如上图所示，当父进程调用 <code>fork</code> 创建子进程时，父进程的 <code>虚拟内存页</code>与子进程的 <code>虚拟内存页</code> 映射到相同的 <code>物理内存页</code>，并且把父进程和子进程对应的页表中的页表项属性设置为只读（因为设置为只读后，对内存页进行写操作时，CPU将会触发 <code>写保护中断</code>，从而内核可以在中断处理函数中进行物理内存页的复制）。</p>
<p>当子进程对 <code>虚拟内存页</code> 进行写操作，便会触发 <code>写保护中断</code>，这个中断是由于违反权限导致的。在缺页异常处理函数中，操作系统会在「中断处理函数」里进行<strong>物理内存的复制</strong>，并重新设置其内存映射关系，将父、子进程的内存读写权限设置为<strong>可读写</strong>，最后才会对内存进行写操作。</p>
<p>这样做的好处有两个：</p>
<ul>
<li>加速创建子进程的速度。</li>
<li>减少进程对物理内存的使用。</li>
</ul>
<blockquote>
<p>注意：有写时复制的过程，如果主线程第一次进行修改，就会发生写时复制，如果主线程再对同一个数据进行写操作，这时就不需要复制。</p>
</blockquote>
<p><strong>写时复制技术如何判断有其它进程在共享这块内存：</strong></p>
<p>fork()会复制父进程的页表给子进程，并把所有当前正常状态的数据段、堆和栈空间的虚拟内存页<strong>设置为不可写，然后把已经映射的物理页面的引用计数加 1。</strong>这一步只需要复制页表和修改页表项中的写权限位可以了。</p>
<p>父进程或子进程发生写操作时，会触发写保护中断，内核会调用写保护中断处理函数，<strong>系统首先判断发生中断的虚拟内存地址对应的物理内存地址的引用计数，如果大于0，就说明存在多个进程共享这一块物理内存</strong>，那么就会为触发中断的进程拷贝一份该物理内存。</p>
<p><strong>写时复制操作仍然有两个阶段会导致阻塞父进程：</strong></p>
<ul>
<li>页表越大，阻塞的时间也越长：创建子进程的途中，由于要复制父进程的页表等数据结构，阻塞的时间跟页表的大小有关。</li>
<li>写时复制的内存越大，阻塞的时间也越长：创建完子进程后，如果子进程或者父进程修改了共享数据，就会发生写时复制，这期间会拷贝物理内存。</li>
</ul>
<p>子进程重写过程中，主进程依然可以正常处理命令。如果此时<strong>主进程修改了已经存在 key-value，就会发生写时复制，注意这里只会复制主进程修改的物理内存数据，没修改的物理内存还是与子进程共享的</strong>。</p>
<p>重写 AOF 日志过程中，主进程修改已存在的键值对，会造成<strong>子进程与主进程内存数据不一致的现象</strong>，Redis的解决方法是：</p>
<blockquote>
<p>1、Redis 设置了一个 <strong>AOF 重写缓冲区</strong>，这个缓冲区在创建 bgrewriteaof 子进程之后开始使用。在重写 AOF 期间，当 Redis 执行完一个写命令之后，它会<strong>同时将这个写命令写入到 「AOF 缓冲区」和 「AOF 重写缓冲区」</strong>。</p>
<p>2、当子进程完成 AOF 重写工作（<em>扫描数据库所有数据，记录键值对最终版本到新AOF日志文件中</em>）后，会向主进程发送一条信号，信号是进程间通讯的一种方式，且是异步的。</p>
<p>主进程收到该信号后，会调用一个信号处理函数，该函数主要做以下工作：</p>
<ul>
<li>将 AOF 重写缓冲区中的所有内容追加到新的 AOF 的文件中，使得新旧两个 AOF 文件所保存的数据库状态一致；</li>
<li>新的 AOF 的文件进行改名，覆盖现有的 AOF 文件。</li>
</ul>
</blockquote>
<p><strong>综上，在 bgrewriteaof 子进程执行 AOF 重写期间，主进程需要执行以下三个工作:</strong></p>
<ul>
<li>执行客户端发来的命令；</li>
<li>将执行后的写命令追加到 「AOF 缓冲区」；</li>
<li>将执行后的写命令追加到 「AOF 重写缓冲区」；</li>
</ul>
<p><img src="https://s2.loli.net/2022/11/14/7xm62FyAwp9SgPK.png" alt="image-20221114235135007"></p>
<p><strong>归纳AOF后台重写容易发送阻塞的过程：</strong></p>
<ul>
<li>写时复制可能会对主进程造成阻塞</li>
<li>信号处理函数执行时，将AOF重写缓冲区文件添加到新的AOF文件中。</li>
</ul>
<h2 id="RDB持久化"><a href="#RDB持久化" class="headerlink" title="RDB持久化"></a>RDB持久化</h2><p>RDB 持久化记录的某一个瞬间的内存数据。</p>
<p>RDB日志文件的内容是二进制数据。</p>
<p>优点</p>
<ul>
<li>存储紧凑，节省内存空间。</li>
<li>恢复速度非常快。</li>
<li>适合全量备份、全量复制的场景，经常用于灾难恢复（对数据的完整性和一致性要求相对较低的场合）。</li>
</ul>
<p>缺点</p>
<ul>
<li>容易丢失数据，容易丢失两次快照之间 Redis 服务器中变化的数据。</li>
<li>RDB 通过 fork 子进程对内存快照进行全量备份，是一个重量级操作，频繁执行成本高。</li>
</ul>
<h3 id="RDB文件创建"><a href="#RDB文件创建" class="headerlink" title="RDB文件创建"></a>RDB文件创建</h3><p><strong>手动指令触发</strong></p>
<p>手动触发 RDB 持久化的方式可以使用 <code>save</code> 命令和 <code>bgsave</code> 命令，这两个命令的区别如下：</p>
<ul>
<li><p><code>save</code>：执行<code>save</code>指令，阻塞 Redis 的其他操作，会导致 Redis 无法响应客户端请求，不建议使用。</p>
</li>
<li><p><code>bgsave</code>：执行 <code>bgsave</code> 指令，Redis 后台创建子进程，异步进行快照的保存操作，此时 Redis 仍然能响应客户端的请求。</p>
</li>
</ul>
<p><strong>自动间隔性保存</strong></p>
<p>在默认情况下，Redis 将数据库快照保存在名字为 dump.rdb的二进制文件中。可以对 Redis 进行设置，让它在“ N 秒内数据集至少有 M 个改动”这一条件被满足时，自动保存一次数据集。</p>
<p>Redis 的默认配置如下，三个设置满足其一即可触发自动保存：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">save</span> <span class="number">60</span> <span class="number">10000</span>    <span class="comment"># 60 秒之内，对数据库进行了至少 10000 次修改。</span></span><br><span class="line"><span class="string">save</span> <span class="number">300</span> <span class="number">10</span>      <span class="comment"># 300 秒之内，对数据库进行了至少 10 次修改；</span></span><br><span class="line"><span class="string">save</span> <span class="number">900</span> <span class="number">1</span>       <span class="comment"># 900 秒之内，对数据库进行了至少 1 次修改；</span></span><br></pre></td></tr></table></figure>

<h3 id="RDB持久化过程"><a href="#RDB持久化过程" class="headerlink" title="RDB持久化过程"></a>RDB持久化过程</h3><p>RDB 持久化方案进行备份时，Redis 会单独 fork 一个子进程来进行持久化，会将数据写入一个临时文件中，持久化完成后替换旧的 RDB 文件。在整个持久化过程中，主进程（为客户端提供服务的进程）不参与 IO 操作，这样能确保 Redis 服务的高性能，RDB 持久化机制适合对数据完整性要求不高但追求高效恢复的使用场景。下面展示 RDB 持久化流程：</p>
<p><img src="https://s2.loli.net/2022/11/15/2SlPNzjYyipCBmb.png" alt="image-20221115152643278"></p>
<p>关键执行步骤如下</p>
<ol>
<li>Redis 父进程首先判断：当前是否在执行 save，或 bgsave&#x2F;bgrewriteaof 的子进程，如果在执行bgsave 命令则直接返回。bgsave&#x2F;bgrewriteaof 的子进程不能同时执行，主要是基于性能方面的考虑：两个并发的子进程同时执行大量的磁盘写操作，可能引起严重的性能问题。</li>
<li>父进程执行 fork 操作创建子进程，这个过程中父进程是阻塞的，Redis 不能执行来自客户端的任何命令。父进程 fork 后，bgsave 命令返回”Background saving started”信息并不再阻塞父进程，并可以响应其他命令。</li>
<li>子进程进程对内存数据生成快照文件。</li>
<li>父进程在此期间接收的新的写操作，使用 写时复制机制 写入。</li>
<li>子进程完成快照写入，替换 旧的RDB文件，随后子进程退出。</li>
</ol>
<p><strong>Fork子进程的作用：</strong></p>
<p><strong>Redis 在持久化时调用 glibc 函数 fork 一个子进程，全权负责持久化工作，这样父进程仍然能继续给客户端提供服务</strong>。fork 的子进程初始时与父进程（Redis 的主进程）共享同一块内存；当持久化过程中，客户端的请求对内存中的数据进行修改，此时就会通过 COW (Copy On Write) 机制对数据段页面进行分离，也就是复制一块内存出来给主进程去修改。</p>
<p><img src="https://s2.loli.net/2022/11/15/UR8S2VwyiIGfk1c.png" alt="image-20221115155056344"></p>
<p><strong>AOF和RDB之间的相互作用：</strong></p>
<p>在版本号大于等于2.4的 Redis 中，bgsave执行的过程中，不可以执行 bgrewriteaof。反过来说，在 bgrewriteaof执行的过程中，也不可以执行 bgsave。这可以防止两个 Redis 后台进程同时对磁盘进行大量的 I&#x2F;O 操作。</p>
<p>如果 bgsave正在执行，并且用户显示地调用 bgrewriteaof命令，那么服务器将向用户回复一个 OK 状态，并告知用户，bgrewriteaof已经被预定执行：一旦 bgsave执行完毕 bgrewriteaof就会正式开始。</p>
<p>当 Redis 启动时，如果 RDB 持久化和 AOF 持久化都被打开了，那么程序会优先使用 AOF 文件来恢复数据集，因为 AOF 文件所保存的数据通常是最完整的。</p>
<h2 id="混合持久化"><a href="#混合持久化" class="headerlink" title="混合持久化"></a>混合持久化</h2><h3 id="混合持久化介绍"><a href="#混合持久化介绍" class="headerlink" title="混合持久化介绍"></a>混合持久化介绍</h3><p>Redis从4.0版本开始引入 RDB-AOF 混合持久化模式，这种模式是基于 AOF 持久化模式构建而来的，混合持久化通过 <code>aof-use-rdb-preamble yes</code> 开启。</p>
<p>混合持久化兼顾AOF和RDB的优势：</p>
<blockquote>
<p> RDB 恢复速度很快，但是会丢失比较多的数据，不能保证数据完整性</p>
<p>AOF能尽可能保证数据完整性，但是性能不是最佳，比如重放恢复数据</p>
</blockquote>
<h3 id="混合持久化工作过程"><a href="#混合持久化工作过程" class="headerlink" title="混合持久化工作过程"></a>混合持久化工作过程</h3><p><strong>生成日志文件</strong></p>
<ul>
<li><p>Redis 服务器在执行 AOF 重写操作时，就会像执行 BGSAVE 命令那样，根据数据库当前的状态生成出相应的 RDB 数据，并将这些数据写入新建的 AOF 文件中</p>
</li>
<li><p>至于那些在 AOF 重写开始之后执行的 Redis 命令，则会继续以协议文本的方式追加到新 AOF 文件的末尾，即已有的 RDB 数据的后面。</p>
</li>
</ul>
<p>综上所述：服务器生成的 AOF 文件将由两个部分组成，其中位于 AOF 文件开头的是 RDB 格式的数据，而跟在 RDB 数据后面的则是 AOF 格式的数据。</p>
<p><strong>载入日志文件</strong></p>
<p>当一个支持 RDB-AOF 混合持久化模式的 Redis 服务器启动并载入 AOF 文件时，它会检查 AOF 文件的开头是否包含了 RDB 格式的内容。</p>
<ul>
<li>如果包含，那么服务器就会先载入开头的 RDB 数据，然后再载入之后的 AOF 数据。</li>
<li>如果 AOF 文件只包含 AOF 数据，那么服务器将直接载入 AOF 数据。</li>
</ul>
<p><img src="https://s2.loli.net/2022/11/15/TWpZkIQUlvx1Ywa.png" alt="image-20221115170532308"></p>
]]></content>
      <categories>
        <category>缓存数据库</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis底层数据结构详解</title>
    <url>/p/3ee873cb/</url>
    <content><![CDATA[<h2 id="键值对数据库实现"><a href="#键值对数据库实现" class="headerlink" title="键值对数据库实现"></a>键值对数据库实现</h2><p>Redis 使用了一个「哈希表」保存所有键值对，哈希表的最大好处就是让我们可以用 O(1) 的时间复杂度来快速查找到键值对。哈希表其实就是一个数组，数组中的元素叫做哈希桶。</p>
<p>Redis 的键值对中的 <strong>key 就是字符串对象</strong>，而 <strong>value 可以是字符串对象，也可以是集合数据类型的对象</strong>，比如 List 对象、Hash 对象、Set 对象和 Zset 对象。</p>
<span id="more"></span>

<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//Redis 中的每个对象都由 redisObject 结构表示</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">redisObject</span> &#123;</span></span><br><span class="line">    <span class="type">unsigned</span> type:<span class="number">4</span>;        <span class="comment">//类型</span></span><br><span class="line">    <span class="type">unsigned</span> encoding:<span class="number">4</span>;    <span class="comment">//编码</span></span><br><span class="line">    <span class="type">unsigned</span> lru:LRU_BITS; <span class="comment">//记录了最后一次被命令程序访问的时间</span></span><br><span class="line">    					  <span class="comment">/* LRU time (relative to global lru_clock) or</span></span><br><span class="line"><span class="comment">                            * LFU data (least significant 8 bits frequency</span></span><br><span class="line"><span class="comment">                            * and most significant 16 bits access time). */</span></span><br><span class="line">    <span class="type">int</span> refcount; <span class="comment">//引用计数</span></span><br><span class="line">    <span class="type">void</span> *ptr;  <span class="comment">//指向底层实现数据结构的指针</span></span><br><span class="line">&#125; robj;</span><br></pre></td></tr></table></figure>

<p><strong>对象类型：</strong></p>
<table>
<thead>
<tr>
<th align="center">类型常量</th>
<th align="center">对象的名称</th>
<th align="center">TYPE命令输出</th>
</tr>
</thead>
<tbody><tr>
<td align="center">REDIS_STRING</td>
<td align="center">字符串对象</td>
<td align="center">“string”</td>
</tr>
<tr>
<td align="center">REDIS_LIST</td>
<td align="center">列表对象</td>
<td align="center">“list”</td>
</tr>
<tr>
<td align="center">REDIS_HASH</td>
<td align="center">哈希对象</td>
<td align="center">“hash”</td>
</tr>
<tr>
<td align="center">REDIS_SET</td>
<td align="center">集合对象</td>
<td align="center">“set”</td>
</tr>
<tr>
<td align="center">REDIS_ZSET</td>
<td align="center">有序集合对象</td>
<td align="center">“zset”</td>
</tr>
</tbody></table>
<p><strong>不同类型的编码对象：</strong></p>
<table>
<thead>
<tr>
<th align="center">类型</th>
<th align="center">编码</th>
<th align="center">对象</th>
</tr>
</thead>
<tbody><tr>
<td align="center">REDIS_STRING</td>
<td align="center">REDIS_ENCODING_INT</td>
<td align="center">整数值—&gt;字符串对象</td>
</tr>
<tr>
<td align="center">REDIS_STRING</td>
<td align="center">REDIS_ENCODING_EMBSTR</td>
<td align="center">embstr编码的SDS—&gt;字符串对象</td>
</tr>
<tr>
<td align="center">REDIS_STRING</td>
<td align="center">REDIS_ENCODING_RAW</td>
<td align="center">SDS—&gt;字符串对象</td>
</tr>
<tr>
<td align="center">REDIS_LIST</td>
<td align="center">REDIS_ENCODING_ZIPLIST</td>
<td align="center">压缩列表—&gt;列表对象</td>
</tr>
<tr>
<td align="center">REDIS_LIST</td>
<td align="center">REDIS_ENCODING_LINKEDLIST</td>
<td align="center">双向链表—&gt;列表对象</td>
</tr>
<tr>
<td align="center">REDIS_HASH</td>
<td align="center">REDIS_ENCODING_ZIPLIST</td>
<td align="center">压缩列表—&gt;哈希对象</td>
</tr>
<tr>
<td align="center">REDIS_HASH</td>
<td align="center">REDIS_ENCODING_HT</td>
<td align="center">字典—&gt;哈希对象</td>
</tr>
<tr>
<td align="center">REDIS_SET</td>
<td align="center">REDIS_ENCODING_INTSET</td>
<td align="center">整数集合—&gt;集合对象</td>
</tr>
<tr>
<td align="center">REDIS_SET</td>
<td align="center">REDIS_ENCODING_HT</td>
<td align="center">字典—&gt;集合对象</td>
</tr>
<tr>
<td align="center">REDIS_ZSET</td>
<td align="center">REDIS_ENCODING_ZIPLIST</td>
<td align="center">压缩列表—&gt;有序集合对象</td>
</tr>
<tr>
<td align="center">REDIS_ZSET</td>
<td align="center">REDIS_ENCODING_SKIPLIST</td>
<td align="center">跳表+字典—&gt;有序集合对象</td>
</tr>
</tbody></table>
<p><strong>引用计数实现内存回收：</strong></p>
<p>Redis在自己的对象系统构建了一个引用计数技术来实现内存回收机制。每个对象的引用计数信息由<code>redisObject</code>结构的<code>refcount</code>属性记录。引用计数会随着对象使用状态变化而不断变化。</p>
<ul>
<li>在创建一个新对象时，引用计数的值会被初始化为1（被服务器程序引用）</li>
<li>当对象被一个新程序使用时，它的引用计数值会增加1</li>
<li>当对象不再被一个对象使用时，它的引用计数值会减1</li>
<li>当对象的引用计数值变为0时，对象所占用的内存会被释放。</li>
</ul>
<p><strong>对象共享：</strong></p>
<p><code>refcount</code>属性还被用于整数值对象共享，实现多个键对象共享一个值对象。比如键A,键B都包含整数值100，那么键A和键B共享同一个字符串对象。</p>
<p>共享步骤：</p>
<ul>
<li>将数据库键的值指针指向一个现有的值对象</li>
<li>将被共享的值对象的引用计数refcount增加1.</li>
</ul>
<p>Redis会在初始化服务器时创建一万个字符串对象，这些对象包括从0到9999的所有整数值。</p>
<blockquote>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> OBJ_SHARED_INTEGERS 10000 <span class="comment">//server.h文件下，可以调整创建共享对象的数量</span></span></span><br></pre></td></tr></table></figure>
</blockquote>
<p><strong>对象空转时长：</strong></p>
<p>通过<code>lru</code>属性记录对象最后一次被命令访问的时间。可以通过<code>OBJECT IDLETIME</code>命令，通过当前时间减去对象的lru时间获取空转时长。</p>
<p><img src="https://s2.loli.net/2022/11/09/qWEZ5NwxkGhPzcn.png" alt="image-20221109150800658"></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**表示redis数据库。有多个数据库，用从0(默认数据库)到最大配置数据库的整数标识。数据库编号是结构中的&#x27;id&#x27;字段。*/</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">redisDb</span> &#123;</span></span><br><span class="line">    dict *dict;                 <span class="comment">/**数据库键空间*/</span> <span class="comment">/* The keyspace for this DB */</span></span><br><span class="line">    dict *expires;              <span class="comment">/**设置了超时的键的超时时间*/</span></span><br><span class="line">    dict *blocking_keys;        <span class="comment">/* Keys with clients waiting for data (BLPOP)*/</span></span><br><span class="line">    dict *ready_keys;           <span class="comment">/* Blocked keys that received a PUSH */</span></span><br><span class="line">    dict *watched_keys;         <span class="comment">/* WATCHED keys for MULTI/EXEC CAS */</span></span><br><span class="line">    <span class="type">int</span> id;                     <span class="comment">/**数据库ID*/</span> <span class="comment">/* Database ID */</span></span><br><span class="line">    <span class="type">long</span> <span class="type">long</span> avg_ttl;          <span class="comment">/* Average TTL, just for stats */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> expires_cursor; <span class="comment">/* Cursor of the active expire cycle. */</span></span><br><span class="line">    <span class="built_in">list</span> *defrag_later;         <span class="comment">/* List of key names to attempt to defrag one by one, gradually. */</span></span><br><span class="line">&#125; redisDb;</span><br></pre></td></tr></table></figure>

<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**字典结构*/</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">dict</span> &#123;</span></span><br><span class="line">    dictType *type;</span><br><span class="line">    <span class="type">void</span> *privdata;</span><br><span class="line">    dictht ht[<span class="number">2</span>];    <span class="comment">/**正常情况使用「哈希表1」，「哈希表2」只有在 rehash 的时候才用*/</span></span><br><span class="line">    <span class="type">long</span> rehashidx; <span class="comment">/* 没有进行rehash 如果rehashidx == -1 */</span></span><br><span class="line">    <span class="type">int16_t</span> pauserehash; <span class="comment">/*大于0表示暂停 (&lt;0 indicates coding error) */</span></span><br><span class="line">&#125; dict;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**哈希表结构。当我们实现从旧表到新表rehash时，每个字典都有两个这样的结构。 */</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">dictht</span> &#123;</span></span><br><span class="line">    dictEntry **table;      <span class="comment">//哈希表数组</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> size;     <span class="comment">//哈希表大小</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> sizemask; <span class="comment">//哈希表大小掩码，用于计算索引值</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> used;     <span class="comment">//该哈希表已有的节点数量</span></span><br><span class="line">&#125; dictht;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**哈希表节点结构*/</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">dictEntry</span> &#123;</span></span><br><span class="line">    <span class="type">void</span> *key;    <span class="comment">/**指向的是String对象*/</span></span><br><span class="line">    <span class="class"><span class="keyword">union</span> &#123;</span></span><br><span class="line">        <span class="type">void</span> *val;  <span class="comment">/** 可指向 String 对象，也可指向集合类型的对象，比如 List 、Hash 、Set和 Zset 对象。*/</span></span><br><span class="line">        <span class="type">uint64_t</span> u64;</span><br><span class="line">        <span class="type">int64_t</span> s64;</span><br><span class="line">        <span class="type">double</span> d;</span><br><span class="line">    &#125; v;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">dictEntry</span> *<span class="title">next</span>;</span> <span class="comment">/**指向下一个哈希表节点，形成链表，解决哈希冲突*/</span></span><br><span class="line">&#125; dictEntry;</span><br></pre></td></tr></table></figure>

<p>哈希桶存放的是指向键值对数据的指针（dictEntry*），这样通过指针就能找到键值对数据，然后因为键值对的值可以保存字符串对象和集合数据类型的对象，所以键值对的数据结构中并不是直接保存值本身，而是保存了 void * key 和 void * value 指针，分别指向了实际的键对象和值对象，这样一来，即使值是集合数据，也可以通过 void * value 指针找到。</p>
<p><img src="https://s2.loli.net/2022/11/09/VWqZaHsn6Kgzf42.png" alt="img"></p>
<h2 id="SDS"><a href="#SDS" class="headerlink" title="SDS"></a>SDS</h2><p> Redis 的 String 数据类型的底层数据结构是 SDS。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> __<span class="title">attribute__</span> ((__<span class="title">packed__</span>)) <span class="title">sdshdr32</span> &#123;</span></span><br><span class="line">    <span class="type">uint32_t</span> len; <span class="comment">/** 记录了字符串长度 */</span></span><br><span class="line">    <span class="type">uint32_t</span> alloc; <span class="comment">/** 分配的空间长度 （不包含头部的和空结束符号） */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">char</span> flags; <span class="comment">/** 用来表示不同类型的 SDS */</span></span><br><span class="line">    <span class="type">char</span> buf[]; <span class="comment">/** 字符数组，用来保存实际数据 */</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">//sdshdr32 类型的 len 和 alloc 的数据类型都是 uint32_t，表示字符数组长度和分配空间大小不能超过 2 的 32 次方</span></span><br><span class="line"><span class="comment">//之所以 SDS 设计不同类型的结构体，是为了能灵活保存不同大小的字符串，从而有效节省内存空间。比如，在保存小字符串时，结构头占用空间也比较少。</span></span><br></pre></td></tr></table></figure>

<p><strong>sds结构中成员变量解释：</strong></p>
<ul>
<li><p><strong>len（记录字符串长度）：</strong>这样获取字符串长度时避免了遍历，可以直接返回len，时间复杂度O(1)。</p>
</li>
<li><p><strong>alloc（分配给字符数组的长度）：</strong>在修改字符串的时候，可以通过 <code>alloc - len</code> 计算出剩余的空间大小，来判断空间是否满足修改需求，如果不满足的话，可以自动扩容。所以使用 SDS 既不需要手动操作 SDS 的空间大小，也不会出现前面所说的缓冲区溢出的问题。</p>
</li>
<li><p><strong>flags（表示不同类型的 SDS）：</strong>一共设计了 5 种类型，分别是 sdshdr5、sdshdr8、sdshdr16、sdshdr32 和 sdshdr64。</p>
</li>
<li><p><strong>buf[]（字符数组，用来保存实际数据）：</strong>不仅可以保存字符串，也可以保存二进制数据。</p>
</li>
</ul>
<p><strong>SDS结构的优点</strong>：</p>
<ol>
<li><p><strong>能做到O(1)的时间复杂度获取字符串长度</strong>：SDS 结构因为加入了 len 成员变量</p>
</li>
<li><p><strong>二进制安全</strong>：有个专门的 len 成员变量来记录长度，所以可存储包含 “\0” 的数据，无需像C语言那样依赖<code>\0</code>表示字符串结尾（但是 SDS 为了兼容部分 C 语言标准库的函数， SDS 字符串结尾还是会加上 “\0” 字符。）。使得 Redis 不仅可以保存文本数据，也可以保存任意格式的二进制数据。</p>
</li>
<li><p><strong>不会发生缓冲区溢出</strong>：Redis 的 SDS 结构里引入了 alloc 和 len 成员变量，这样 SDS API 通过 <code>alloc - len</code> 计算，可以算出剩余可用的空间大小，这样在对字符串做修改操作的时候，就可以由程序内部判断缓冲区大小是否足够用。当判断出缓冲区大小不够用时，Redis 会自动将扩大 SDS 的空间大小。</p>
<p>扩容规则：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">sds <span class="title function_">sdsMakeRoomFor</span><span class="params">(sds s, <span class="type">size_t</span> addlen)</span> &#123;</span><br><span class="line">    ......</span><br><span class="line">    <span class="comment">/* Return ASAP if there is enough space left. */</span></span><br><span class="line">    <span class="comment">/** s目前的剩余空间已足够，无需扩展，直接返回*/</span></span><br><span class="line">    <span class="keyword">if</span> (avail &gt;= addlen) <span class="keyword">return</span> s;</span><br><span class="line"></span><br><span class="line">    len = sdslen(s);</span><br><span class="line">    sh = (<span class="type">char</span>*)s-sdsHdrSize(oldtype);</span><br><span class="line">    <span class="comment">/**扩展之后 s 至少需要的长度*/</span></span><br><span class="line">    reqlen = newlen = (len+addlen);</span><br><span class="line">    assert(newlen &gt; len);   <span class="comment">/* Catch size_t overflow */</span></span><br><span class="line">    <span class="comment">/**根据新长度，为s分配新空间所需的大小*/</span></span><br><span class="line">    <span class="keyword">if</span> (newlen &lt; SDS_MAX_PREALLOC)</span><br><span class="line">        newlen *= <span class="number">2</span>; <span class="comment">/**新长度 &lt; 1MB 则分配所需空间*2的空间*/</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="comment">/**否则，分配长度为目前长度+1MB*/</span></span><br><span class="line">        newlen += SDS_MAX_PREALLOC;</span><br><span class="line">    ......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><p>如果所需的 sds 长度<strong>小于 1 MB</strong>，那么最后的扩容是按照<strong>翻倍扩容</strong>来执行的，即 2 倍的newlen</p>
</li>
<li><p>如果所需的 sds 长度<strong>超过 1 MB</strong>，那么最后的扩容长度应该是 newlen <strong>+ 1MB</strong>。</p>
</li>
</ul>
<p>这样的好处是，下次在操作 SDS 时，如果 SDS 空间够的话，API 就会直接使用「未使用空间」，而无须执行内存分配，<strong>有效的减少内存分配次数</strong>。</p>
</li>
<li><p><strong>节省内存空间</strong>：SDS 结构中有个 flags 成员变量，表示的是 SDS 类型。Redis 一共设计了 5 种结构体类型，分别是 sdshdr5、sdshdr8、sdshdr16、sdshdr32 和 sdshdr64。</p>
<ul>
<li><p>这 5 种类型的主要区别就在于，它们数据结构中的 len 和 alloc 成员变量的数据类型不同。<strong>能灵活保存不同大小的字符串，从而有效节省内存空间。比如，在保存小字符串时，结构头占用空间也比较少。</strong></p>
</li>
<li><p>除了设计不同类型的结构体，Redis 在编程上还<strong>使用了专门的编译优化来节省内存空间</strong>，即在 struct 声明了 <code>__attribute__ ((__packed__))</code> ，它的作用是：<strong>告诉编译器取消结构体在编译过程中的优化对齐，按照实际占用字节数进行对齐</strong>。</p>
<blockquote>
<p>比如，sdshdr16 类型的 SDS，默认情况下，编译器会按照 2 字节对齐的方式给变量分配内存，这意味着，即使一个变量的大小不到 2 个字节，编译器也会给它分配 2 个字节。</p>
</blockquote>
</li>
</ul>
</li>
</ol>
<p><strong>优化对齐理解</strong></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">假设下面的结构体，它有两个成员变量，类型分别是 <span class="type">char</span> 和 <span class="type">int</span>:</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">test1</span> &#123;</span></span><br><span class="line">    <span class="type">char</span> a;</span><br><span class="line">    <span class="type">int</span> b;</span><br><span class="line">&#125; test1; </span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">     <span class="built_in">printf</span>(<span class="string">&quot;%lu\n&quot;</span>, <span class="keyword">sizeof</span>(test1));</span><br><span class="line">     <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line">打印：<span class="number">8</span></span><br></pre></td></tr></table></figure>

<p>默认情况下，编译器是使用「字节对齐」的方式分配内存，虽然 char 类型只占一个字节，但是由于成员变量里有 int 类型，它占用了 4 个字节，所以在成员变量为 char 类型分配内存时，会分配 4 个字节，其中这多余的 3 个字节是为了字节对齐而分配的，相当于有 3 个字节被浪费掉了。</p>
<p><img src="https://s2.loli.net/2022/11/09/hYdoWONAGbjkv1C.png" alt="img"></p>
<p>如果不想编译器使用字节对齐的方式进行分配内存，可以采用了 <code>__attribute__ ((packed))</code> 属性定义结构体，这时打印的结果会是 5（1 个字节 char + 4 字节 int）。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> __<span class="title">attribute__</span>((<span class="title">packed</span>)) <span class="title">test2</span>  &#123;</span></span><br><span class="line">    <span class="type">char</span> a;</span><br><span class="line">    <span class="type">int</span> b;</span><br><span class="line"> &#125; test2;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">     <span class="built_in">printf</span>(<span class="string">&quot;%lu\n&quot;</span>, <span class="keyword">sizeof</span>(test2));</span><br><span class="line">     <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line">打印：<span class="number">5</span></span><br></pre></td></tr></table></figure>

<p><img src="https://s2.loli.net/2022/11/09/h7E9FtmBbiLJGrx.png" alt="img"></p>
<h2 id="链表"><a href="#链表" class="headerlink" title="链表"></a>链表</h2><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**链表结构*/</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">list</span> &#123;</span></span><br><span class="line">    listNode *head; <span class="comment">/**链表头结点*/</span></span><br><span class="line">    listNode *tail; <span class="comment">/**链表尾结点*/</span></span><br><span class="line">    <span class="type">void</span> *(*dup)(<span class="type">void</span> *ptr);  <span class="comment">/**节点复制函数*/</span></span><br><span class="line">    <span class="type">void</span> (*<span class="built_in">free</span>)(<span class="type">void</span> *ptr);  <span class="comment">/**节点释放函数*/</span></span><br><span class="line">    <span class="type">int</span> (*match)(<span class="type">void</span> *ptr, <span class="type">void</span> *key); <span class="comment">/**节点比较函数*/</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> len;  <span class="comment">/**链表节点的数量*/</span></span><br><span class="line">&#125; <span class="built_in">list</span>;</span><br></pre></td></tr></table></figure>

<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**链表节点*/</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">listNode</span> &#123;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">listNode</span> *<span class="title">prev</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">listNode</span> *<span class="title">next</span>;</span></span><br><span class="line">    <span class="type">void</span> *value;</span><br><span class="line">&#125; listNode;</span><br></pre></td></tr></table></figure>

<p><strong>链表的优点：</strong></p>
<ul>
<li><p>listNode 链表节点的结构里带有 prev 和 next 指针，<strong>获取某个节点的前置节点或后置节点的时间复杂度只需O(1)，而且这两个指针都可以指向 NULL，所以链表是无环链表</strong>；</p>
</li>
<li><p>list 结构因为提供了表头指针 head 和表尾节点 tail，所以**获取链表的表头节点和表尾节点的时间复杂度只需O(1)**；</p>
</li>
<li><p>list 结构因为提供了链表节点数量 len，所以**获取链表中的节点数量的时间复杂度只需O(1)**；</p>
</li>
<li><p>listNode 链表节使用 <code>void *</code> 指针保存节点值，并且可以通过 list 结构的 dup、free、match 函数指针为节点设置该节点类型特定的函数，因此<strong>链表节点可以保存各种不同类型的值</strong>；</p>
</li>
</ul>
<p><strong>链表的缺点：</strong></p>
<ul>
<li><p>链表每个节点之间的内存都是不连续的，意味着<strong>无法很好利用 CPU 缓存</strong>。能很好利用 CPU 缓存的数据结构就是数组，因为数组的内存是连续的，这样就可以充分利用 CPU 缓存来加速访问。</p>
</li>
<li><p>还有一点，保存一个链表节点的值都需要一个链表节点结构头的分配，<strong>内存开销较大</strong>。</p>
</li>
</ul>
<h2 id="压缩列表"><a href="#压缩列表" class="headerlink" title="压缩列表"></a>压缩列表</h2><p>压缩列表的最大特点，就是它被设计成一种内存紧凑型的数据结构，占用一块连续的内存空间，不仅可以利用 CPU 缓存，而且会针对不同长度的数据，进行相应编码，这种方法可以有效地节省内存开销。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**我们使用这个结构体来接收关于ziplist节点的信息。方便后面进行函数操作</span></span><br><span class="line"><span class="comment"> * 注意，这并不是数据的实际编码方式，只是为了更容易地操作*/</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">zlentry</span> &#123;</span></span><br><span class="line">    <span class="comment">/** 存储下面 prevrawlen 所需要的字节数 */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> prevrawlensize;</span><br><span class="line">    <span class="comment">/** 存储前一个节点的字节长度 */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> prevrawlen;   </span><br><span class="line">    </span><br><span class="line">    <span class="comment">/** 存储下面 len 所需要的字节数 */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> lensize;       </span><br><span class="line">    <span class="comment">/** 存储当前节点的字节长度 */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> len; </span><br><span class="line">    </span><br><span class="line">    <span class="comment">/** prevrawlensize + lensize 当前节点的头部字节，</span></span><br><span class="line"><span class="comment">    * 其实是 prevlen + encoding 两项占用的字节数 */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> headersize;  </span><br><span class="line">    </span><br><span class="line">    <span class="comment">/** 存储当前节点的数据编码格式 */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">char</span> encoding;   </span><br><span class="line">    </span><br><span class="line">    <span class="comment">/** 指向当前节点的指针 */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">char</span> *p;  </span><br><span class="line">&#125; zlentry;</span><br></pre></td></tr></table></figure>

<p><strong>压缩列表</strong></p>
<p>压缩列表是 Redis 为了节约内存而开发的，它是<strong>由连续内存块组成的顺序型数据结构</strong></p>
<p><img src="https://s2.loli.net/2022/11/09/xstvrHyUO1w3iEC.png" alt="img"></p>
<p>压缩列表在表头有三个字段：</p>
<ul>
<li><em><strong>zlbytes</strong></em>，记录整个压缩列表占用对内存字节数；</li>
<li><em><strong>zltail</strong></em>，记录压缩列表「尾部」节点距离起始地址由多少字节，也就是列表尾的偏移量；</li>
<li><em><strong>zllen</strong></em>，记录压缩列表包含的节点数量；</li>
<li><em><strong>zlend</strong></em>，标记压缩列表的结束点，固定值 0xFF（十进制255）。</li>
</ul>
<p>在压缩列表中，要查找定位第一个元素和最后一个元素，可以通过表头三个字段（zllen）的长度直接定位，复杂度是 O(1)。而<strong>查找其他元素时，就没有这么高效了，只能逐个查找，此时的复杂度就是 O(N) 了，因此压缩列表不适合保存过多的元素</strong>。</p>
<p><strong>压缩列表节点</strong></p>
<p><img src="https://s2.loli.net/2022/11/09/bnH4NF856Gokltv.png" alt="img"></p>
<p>压缩列表节点包含三部分内容：</p>
<ul>
<li><em><strong>prevlen</strong></em>，记录了「前一个节点」的长度，目的是为了实现从后向前遍历；</li>
<li><em><strong>encoding</strong></em>，记录了当前节点实际数据的「类型和长度」，类型主要有两种：字符串和整数。</li>
<li><em><strong>data</strong></em>，记录了当前节点的实际数据，类型和长度都由 <code>encoding</code> 决定；</li>
</ul>
<p>往压缩列表中插入数据时，压缩列表就会根据数据类型是字符串还是整数，以及数据的大小，会使用不同空间大小的 prevlen 和 encoding 这两个元素里保存的信息。<strong>这种根据数据大小和类型进行不同的空间大小分配的设计思想，正是 Redis 为了节省内存而采用的</strong>。</p>
<p><strong>prevlen 和 encoding 是如何根据数据的大小和类型来进行不同的空间大小分配？</strong></p>
<p>压缩列表里的每个节点中的 prevlen 属性都记录了「前一个节点的长度」，而且 prevlen 属性的空间大小跟前一个节点长度值有关，比如：</p>
<ul>
<li>如果<strong>前一个节点的长度小于 254 字节</strong>，那么 prevlen 属性需要用 <strong>1 字节的空间</strong>来保存这个长度值；</li>
<li>如果<strong>前一个节点的长度大于等于 254 字节</strong>，那么 prevlen 属性需要用 <strong>5 字节的空间</strong>来保存这个长度值；</li>
</ul>
<p><strong>encoding 属性的空间大小跟数据是字符串还是整数，以及字符串的长度有关</strong></p>
<ul>
<li>如果<strong>当前节点的数据是整数</strong>，则 encoding 会使用 <strong>1 字节的空间</strong>进行编码，也就是 encoding 长度为 1 字节。通过 encoding 确认了整数类型，就可以确认整数数据的实际大小了，比如如果 encoding 编码确认了数据是 int16 整数，那么 data 的长度就是 int16 的大小。</li>
<li>如果<strong>当前节点的数据是字符串，根据字符串的长度大小</strong>，encoding 会使用 <strong>1 字节&#x2F;2字节&#x2F;5字节的空间</strong>进行编码，encoding 编码的前两个 bit 表示数据的类型，后续的其他 bit 标识字符串数据的实际长度，即 data 的长度</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li><p><strong>压缩列表只会用于保存的节点数量不多的场景</strong>，</p>
</li>
<li><p><strong>压缩列表新增某个元素或修改某个元素时，如果空间不不够，压缩列表占用的内存空间就需要重新分配。而当新插入的元素较大时，可能会导致后续元素的 prevlen 占用空间都发生变化，从而引起「连锁更新」问题，导致每个元素的空间都要重新分配，造成访问压缩列表性能的下降</strong>。</p>
</li>
</ul>
<h2 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a>哈希表</h2><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">dictht</span> &#123;</span></span><br><span class="line">    <span class="comment">//哈希表数组</span></span><br><span class="line">    dictEntry **table;</span><br><span class="line">    <span class="comment">//哈希表大小</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> size;  </span><br><span class="line">    <span class="comment">//哈希表大小掩码，用于计算索引值</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> sizemask;</span><br><span class="line">    <span class="comment">//该哈希表已有的节点数量</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> used;</span><br><span class="line">&#125; dictht;</span><br></pre></td></tr></table></figure>

<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">dictEntry</span> &#123;</span></span><br><span class="line">    <span class="comment">//键值对中的键</span></span><br><span class="line">    <span class="type">void</span> *key;</span><br><span class="line">  </span><br><span class="line">    <span class="comment">//键值对中的值</span></span><br><span class="line">    <span class="class"><span class="keyword">union</span> &#123;</span></span><br><span class="line">        <span class="type">void</span> *val;</span><br><span class="line">        <span class="type">uint64_t</span> u64;</span><br><span class="line">        <span class="type">int64_t</span> s64;</span><br><span class="line">        <span class="type">double</span> d;</span><br><span class="line">    &#125; v;</span><br><span class="line">    <span class="comment">//指向下一个哈希表节点，形成链表</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">dictEntry</span> *<span class="title">next</span>;</span></span><br><span class="line">&#125; dictEntry;</span><br></pre></td></tr></table></figure>

<p>dictEntry 结构里键值对中的值是一个「联合体 v」定义的，因此，<strong>键值对中的值可以是一个指向实际值的指针，或者是一个无符号的 64 位整数或有符号的 64 位整数或double 类的值。这么做的好处是可以节省内存空间</strong>，因为当「值」是整数或浮点数时，就可以将值的数据内嵌在 dictEntry 结构里，无需再用一个指针指向实际的值，从而节省了内存空间。</p>
<p>Redis 采用了「<strong>链式哈希</strong>」的方法来解决哈希冲突。</p>
<p>随着链表长度的增加，在查询桶中某一位置上的数据的耗时就会增加，因为链表的查询时间复杂度是O(n)。这时就需要进行rehash。</p>
<p><strong>rehash</strong></p>
<p>Redis 使用 dictht 结构体表示哈希表。不过，在实际使用哈希表时，Redis 定义一个 dict 结构体，这个结构体里定义了<strong>两个哈希表（ht[2]）</strong></p>
<p><img src="https://s2.loli.net/2022/11/09/GLEmWsHwlY9iPQS.png" alt="img"></p>
<p>在正常服务请求阶段，插入的数据，都会写入到「哈希表 1」，此时的「哈希表 2 」 并没有被分配空间。</p>
<p>随着数据逐步增多，触发了 rehash 操作，这个过程分为三步：</p>
<ul>
<li>给「哈希表 2」 分配空间，一般会比「哈希表 1」 大 2 倍；</li>
<li>将「哈希表 1 」的数据迁移到「哈希表 2」 中；</li>
<li>迁移完成后，「哈希表 1 」的空间会被释放，并把「哈希表 2」 设置为「哈希表 1」，然后在「哈希表 2」 新创建一个空白的哈希表，为下次 rehash 做准备。</li>
</ul>
<p>rehash第二步：<strong>如果「哈希表 1 」的数据量非常大，那么在迁移至「哈希表 2 」的时候，因为会涉及大量的数据拷贝，此时可能会对 Redis 造成阻塞，无法服务其他请求</strong>。</p>
<p><strong>渐进式rehash</strong></p>
<p>渐进式 rehash 步骤如下：</p>
<ul>
<li>给「哈希表 2」 分配空间；</li>
<li><strong>在 rehash 进行期间，每次哈希表元素进行新增、删除、查找或者更新操作时，Redis 除了会执行对应的操作之外，还会顺序将「哈希表 1 」中索引位置上的所有 key-value 迁移到「哈希表 2」 上</strong>；</li>
<li>随着处理客户端发起的哈希表操作请求数量越多，最终在某个时间点会把「哈希表 1 」的所有 key-value 迁移到「哈希表 2」，从而完成 rehash 操作。</li>
</ul>
<p>比如，查找一个 key 的值的话，先会在「哈希表 1」 里面进行查找，如果没找到，就会继续到哈希表 2 里面进行找到。</p>
<p>另外，在渐进式 rehash 进行期间，新增一个 key-value 时，会被保存到「哈希表 2 」里面，而「哈希表 1」 则不再进行任何添加操作</p>
<p><strong>rehash触发条件</strong></p>
<p><img src="https://s2.loli.net/2022/11/09/yV1ShtWXRfPZlNm.png" alt="img"></p>
<ul>
<li><strong>当负载因子大于等于 1</strong> ，并且 Redis 没有在执行 bgsave 命令或者 bgrewiteaof 命令，也就是<strong>没有执行 RDB 快照或没有进行 AOF 重写的时候</strong>，就会进行 rehash 操作。</li>
<li><strong>当负载因子大于等于 5 时</strong>，此时说明哈希冲突非常严重了，不管有没有有在执行 RDB 快照或 AOF 重写，都会强制进行 rehash 操作</li>
</ul>
<h2 id="整数集合"><a href="#整数集合" class="headerlink" title="整数集合"></a>整数集合</h2><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">intset</span> &#123;</span></span><br><span class="line">    <span class="type">uint32_t</span> encoding;     <span class="comment">//编码方式</span></span><br><span class="line">    <span class="type">uint32_t</span> length;       <span class="comment">//集合包含的元素数量</span></span><br><span class="line">    <span class="type">int8_t</span> contents[];     <span class="comment">//存放元素的数组</span></span><br><span class="line">&#125; intset;</span><br></pre></td></tr></table></figure>

<p>保存元素的容器是一个 contents 数组，虽然 contents 被声明为 int8_t 类型的数组，但是实际上 contents 数组并不保存任何 int8_t 类型的元素，contents 数组的真正类型取决于 intset 结构体里的 encoding 属性的值</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//encoding 属性值 </span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> INTSET_ENC_INT16 (sizeof(int16_t))  <span class="comment">// 对应contents 就是一个 int16_t 类型的数组</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> INTSET_ENC_INT32 (sizeof(int32_t))  <span class="comment">// 对应contents 就是一个 int32_t 类型的数组</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> INTSET_ENC_INT64 (sizeof(int64_t))  <span class="comment">// 对应contents 就是一个 int64_t 类型的数组</span></span></span><br></pre></td></tr></table></figure>

<p><strong>整数集合升级操作</strong></p>
<p>规则：就是当我们将一个新元素加入到整数集合里面，如果新元素的类型（int32_t）比整数集合现有所有元素的类型（int16_t）都要长时，整数集合需要先进行升级，也就是按新元素的类型（int32_t）扩展 contents 数组的空间大小。整数集合升级的好处是<strong>节省内存资源</strong>。但是升级后，<strong>是不支持降级操作的</strong></p>
<p><img src="https://s2.loli.net/2022/11/09/gRX5eGUf14Itlik.png" alt="img"></p>
<h2 id="跳表"><a href="#跳表" class="headerlink" title="跳表"></a>跳表</h2><p>Redis 只有 <strong>Zset 对象</strong>的底层实现用到了跳表，跳表的优势是能支持平均 O(logN) 复杂度的节点查找。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">zset</span> &#123;</span></span><br><span class="line">    dict *dict;     <span class="comment">//字典结构</span></span><br><span class="line">    zskiplist *zsl; <span class="comment">//跳表结构</span></span><br><span class="line">&#125; zset;</span><br><span class="line"><span class="comment">//字典+跳表 好处：是既能进行高效的范围查询，也能进行高效单点查询。</span></span><br></pre></td></tr></table></figure>

<p>Zset 对象在使用跳表作为数据结构的时候，是使用由「哈希表+跳表」组成的 struct zset，但是我们讨论的时候，都会说跳表是 Zset 对象的底层数据结构，而不会提及哈希表，是因为 struct zset 中的哈希表只是用于以常数复杂度获取元素权重，大部分操作都是跳表实现的。</p>
<p>Zset 对象能支持范围查询（如 ZRANGEBYSCORE 操作），这是因为它的数据结构设计采用了跳表，而又能以常数复杂度获取元素权重（如 ZSCORE 操作），这是因为它同时利用了哈希表进行索引。</p>
<p><strong>跳表是在链表基础上改进过来的，实现了一种「多层」的有序链表</strong></p>
<p><img src="https://s2.loli.net/2022/11/09/14PUnJ3migeG5Qk.png" alt="img"></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//跳表结构体，作为跳表的头结点</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">zskiplist</span> &#123;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistNode</span> *<span class="title">header</span>, *<span class="title">tail</span>;</span>  <span class="comment">//头，尾节点，O(1)时间复杂度访问跳表的头和尾节点；</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> length;  <span class="comment">//跳表存储元素个数，便于在O(1)时间复杂度获取跳表节点的数量</span></span><br><span class="line">    <span class="type">int</span> level; <span class="comment">//跳表的最大层数，便于在O(1)时间复杂度获取跳表中层高最大的那个节点的层数量；</span></span><br><span class="line">&#125; zskiplist;</span><br></pre></td></tr></table></figure>



<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//跳表节点</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistNode</span> &#123;</span></span><br><span class="line">    sds ele;         <span class="comment">//元素值</span></span><br><span class="line">    <span class="type">double</span> score;    <span class="comment">//权重</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistNode</span> *<span class="title">backward</span>;</span>  <span class="comment">//后退指针，方便从尾结点倒序遍历</span></span><br><span class="line">    <span class="comment">//节点的level数组，保存每层上的前向指针和跨度</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistLevel</span> &#123;</span></span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistNode</span> *<span class="title">forward</span>;</span> <span class="comment">//指向下一个节点</span></span><br><span class="line">        <span class="type">unsigned</span> <span class="type">long</span> span;   <span class="comment">//跨度，实际上是为了计算这个节点在跳表中的排位</span></span><br><span class="line">    &#125; level[];</span><br><span class="line">&#125; zskiplistNode;</span><br></pre></td></tr></table></figure>

<p><strong>跳表查找节点过程</strong></p>
<p>查找一个节点时，会先从最高层开始，逐一遍历每一层。在遍历某一层的跳表节点时，会用跳表节点中的 SDS 类型的元素和元素的权重来进行判断，共有两个判断条件：</p>
<ul>
<li>如果当前节点的权重「小于」要查找的权重时，跳表就会访问该层上的下一个节点。</li>
<li>如果当前节点的权重「等于」要查找的权重时，并且当前节点的 SDS 类型数据「小于」要查找的数据时，跳表就会访问该层上的下一个节点。</li>
</ul>
<p>如果上面两个条件都不满足，或者下一个节点为空时，跳表就会使用目前遍历到的节点的 level 数组里的下一层指针，然后沿着下一层指针继续查找，这就相当于跳到了下一层接着查找。</p>
<p><img src="https://s2.loli.net/2022/11/09/Ytsc9WKFCRnezGT.png" alt="img"></p>
<p>如上图，如果要查找「元素：abcd，权重：4」的节点，查找的过程是这样的：</p>
<ul>
<li>先从头节点的最高层开始，L2 指向了「元素：abc，权重：3」节点，这个节点的权重比要查找节点的小，所以要访问该层上的下一个节点；</li>
<li>但是该层的下一个节点是空节点（ leve[2]指向的是空节点），于是就会跳到「元素：abc，权重：3」节点的下一层去找，也就是 leve[1];</li>
<li>「元素：abc，权重：3」节点的 leve[1] 的下一个指针指向了「元素：abcde，权重：4」的节点，然后将其和要查找的节点比较。虽然「元素：abcde，权重：4」的节点的权重和要查找的权重相同，但是当前节点的 SDS 类型数据「大于」要查找的数据，所以会继续跳到「元素：abc，权重：3」节点的下一层去找，也就是 leve[0]；</li>
<li>「元素：abc，权重：3」节点的 leve[0] 的下一个指针指向了「元素：abcd，权重：4」的节点，该节点正是要查找的节点，查询结束。</li>
</ul>
<p><strong>跳表节点层数的设置</strong></p>
<p>跳表的相邻两层的节点数量最理想的<strong>比例是 2:1</strong>，查找复杂度可以降低到 O(logN)。</p>
<p><strong>怎样才能维持相邻两层的节点数量的比例为 2 : 1 ：</strong></p>
<p>跳表在创建节点的时候，<strong>随机生成每个节点的层数</strong>。</p>
<p>具体的做法是：</p>
<p>跳表在创建节点时候，<strong>会生成范围为[0-1]的一个随机数，如果这个随机数小于 0.25（相当于概率 25%），那么层数就增加 1 层，然后继续生成下一个随机数，直到随机数的结果大于 0.25 结束</strong>，最终确定该节点的层数。</p>
<p>相当于每增加一层的概率不超过 25%，层数越高，概率越低，层高最大限制是 64。</p>
<p><strong>为什么使用跳表不用平衡树？</strong></p>
<p>主要从三个方面考虑：内存占用，对范围查找的支持，实现难易程度</p>
<ul>
<li><strong>从内存占用上来比较，跳表比平衡树更灵活一些</strong>。平衡树每个节点包含 2 个指针（分别指向左右子树），而跳表每个节点包含的指针数目平均为 1&#x2F;(1-p)，具体取决于参数 p 的大小。如果像 Redis里的实现一样，取 p&#x3D;1&#x2F;4，那么平均每个节点包含 1.33 个指针，比平衡树更有优势。</li>
<li><strong>在做范围查找的时候，跳表比平衡树操作要简单</strong>。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在跳表上进行范围查找就非常简单，只需要在找到小值之后，对第 1 层链表进行若干步的遍历就可以实现。</li>
<li><strong>从算法实现难度上来比较，跳表比平衡树要简单得多</strong>。平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而跳表的插入和删除只需要修改相邻节点的指针，操作简单又快速。</li>
</ul>
<h2 id="快速列表（quicklist）"><a href="#快速列表（quicklist）" class="headerlink" title="快速列表（quicklist）"></a>快速列表（quicklist）</h2><p>在 Redis 3.2 的时候，List 对象的底层改由 quicklist 数据结构实现。quicklist 就是「双向链表 + 压缩列表」组合，因为一个 quicklist 就是一个链表，而链表中的每个元素又是一个压缩列表。</p>
<p>对于压缩列表的元素数量增加，或者元素变大了造成连锁更新，性能下降的缺点，quicklist的解决方法是：<strong>通过控制每个链表节点中的压缩列表的大小或者元素个数，来规避连锁更新的问题。因为压缩列表元素越少或越小，连锁更新带来的影响就越小，从而提供了更好的访问性能。</strong></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//quicklist 的结构体</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">quicklist</span> &#123;</span></span><br><span class="line">    quicklistNode *head;   <span class="comment">//quicklist的头部</span></span><br><span class="line">    quicklistNode *tail;   <span class="comment">//尾部</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> count;   <span class="comment">//压缩列表的总元素个数</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> len;     <span class="comment">//quicklistNodes的个数</span></span><br><span class="line">    ......</span><br><span class="line">&#125; quicklist;</span><br></pre></td></tr></table></figure>

<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//quicklistNode 的结构定义</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">quicklistNode</span> &#123;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">quicklistNode</span> *<span class="title">prev</span>;</span>  <span class="comment">/**前一个quicklistNode*/</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">quicklistNode</span> *<span class="title">next</span>;</span>  <span class="comment">/**后一个quicklistNode*/</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">char</span> *zl;           <span class="comment">/**quicklistNode指向的压缩列表*/</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> sz;             <span class="comment">/* 压缩列表的的字节大小 */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> count : <span class="number">16</span>;     <span class="comment">/**压缩列表中的元素个数*/</span></span><br><span class="line">	......</span><br><span class="line">&#125;quicklistNode;</span><br></pre></td></tr></table></figure>

<p>链表节点的元素不再是单纯保存元素值，而是保存了一个压缩列表，所以 quicklistNode 结构体里有个指向压缩列表的指针 *zl。</p>
<p><img src="https://s2.loli.net/2022/11/09/GUQcsItHm7ndMkw.png" alt="img"></p>
<p>在向 quicklist 添加一个元素的时候，会检查插入位置的压缩列表是否能容纳该元素，如果能容纳就直接保存到 quicklistNode 结构里的压缩列表，如果不能容纳，才会新建一个新的 quicklistNode 结构。</p>
<p>quicklist 会控制 quicklistNode 结构里的压缩列表的大小或者元素个数，来规避潜在的连锁更新的风险，但是这并没有完全解决连锁更新的问题。</p>
<h2 id="紧凑列表（listpack）"><a href="#紧凑列表（listpack）" class="headerlink" title="紧凑列表（listpack）"></a>紧凑列表（listpack）</h2><p>Redis 在 5.0 新设计一个数据结构叫 listpack，目的是替代压缩列表，它最大特点是 listpack 中每个节点不再包含前一个节点的长度了，压缩列表每个节点正因为需要保存前一个节点的长度字段，就会有连锁更新的隐患。</p>
<p><img src="https://s2.loli.net/2022/11/09/fCUG6psiKyPtguY.png" alt="img"></p>
<p>listpack 头包含两个属性，分别记录了 listpack 总字节数和元素数量，然后 listpack 末尾也有个结尾标识。图中的 listpack entry 就是 listpack 的节点了。</p>
<p>listpack 采用了压缩列表的很多优秀的设计，比如还是用一块连续的内存空间来紧凑地保存数据，并且为了节省内存的开销，listpack 节点会采用不同的编码方式保存不同大小的数据。</p>
<p> listpack 节点结构:</p>
<p><img src="https://s2.loli.net/2022/11/09/BJv3c27ehodqnlG.png" alt="img"></p>
<p>主要包含三个方面内容：</p>
<ul>
<li>encoding，定义该元素的编码类型，会对不同长度的整数和字符串进行编码；</li>
<li>data，实际存放的数据；</li>
<li>len，encoding+data的总长度；</li>
</ul>
<p>可以看到，<strong>listpack 没有压缩列表中记录前一个节点长度的字段了，listpack 只记录当前节点的长度，当我们向 listpack 加入一个新元素的时候，不会影响其他节点的长度字段的变化，从而避免了压缩列表的连锁更新问题</strong>。</p>
<p><strong>压缩列表的entry为什么要保存prevlen呢？listpack改成len之后不会影响功能吗？</strong></p>
<p>压缩列表的 entry 保存 prevlen 是为了实现节点从后往前遍历，知道前一个节点的长度，就可以计算前一个节点的偏移量。</p>
<p>listpack 一样可以支持从后往前遍历的。<code>listpack.c/lpDecodeBacklen()</code>就可以从当前列表项起始位置的指针开始，向左逐个字节解析，得到前一项的 entry-len 值。</p>
]]></content>
      <categories>
        <category>缓存数据库</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
</search>
